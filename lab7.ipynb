{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Laboratorio 7 - Deep Learning\n",
    "\n",
    "## Autores\n",
    "\n",
    "- Angel Higueros 20460\n",
    "- Fredy Velasquez 201011\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1 - Práctica\n",
    "Considere las arquitecturas conversadas durante la clase, con ello realice una implementación de dos arquitecturas\n",
    "usando PyTorch\n",
    "1. Implemente la arquitectura de LeNet-5 para resolver el problema de clasificación del daset de dígitos escritos a mano llamado mnist dataset\n",
    "2. Implemente la arquitectura de AlexNet para resolver el problema de clasificación usando el dataset de imagenes llamado CIFAR10 dataset.\n",
    "\n",
    "Para cada implementación defina y justifique (dentro del notebook) una métrica de desempeño. Además responda\n",
    "(en su notebook) \n",
    "\n",
    "\n",
    "Recuerde justificar y/o expandir su respuesta:\n",
    "- ¿Cuál es la diferencia principal entre ambas arquitecturas?\n",
    "\n",
    "    - La principal diferencia entre LeNet-5 y AlexNet es su profundidad y complejidad. AlexNet es una red más profunda y contiene más capas convolucionales y totalmente conectadas que LeNet-5.\n",
    "\n",
    "    - AlexNet utiliza la técnica de Dropout para regularización, mientras que LeNet-5 no lo hace.\n",
    "\n",
    "    - AlexNet utiliza la función de activación ReLU en lugar de la función sigmoide utilizada en LeNet-5.\n",
    "    \n",
    "    - AlexNet utiliza capas de agrupación (pooling) y convoluciones con tamaños de kernel más grandes en comparación con LeNet-5.\n",
    "\n",
    "\n",
    "- ¿Podría usarse LeNet-5 para un problema como el que resolvió usando AlexNet? ¿Y viceversa?\n",
    "\n",
    "    - En general, LeNet-5 no sería adecuado para resolver un problema como el de AlexNet en CIFAR-10 debido a su menor profundidad y capacidad limitada para extraer características complejas.\n",
    "\n",
    "    - Por otro lado, AlexNet podría utilizarse para resolver el problema de clasificación de dígitos escritos a mano en el conjunto de datos MNIST, pero sería una elección excesiva en términos de capacidad de la red para este problema relativamente simple.\n",
    "\n",
    "\n",
    "- Indique claramente qué le pareció más interesante de cada arquitectura\n",
    "\n",
    "    - LeNet-5: Lo interesante de LeNet-5 es que fue una de las primeras arquitecturas de CNN desarrolladas y sentó las bases para las redes neuronales convolucionales modernas. A pesar de su simplicidad, pudo lograr buenos resultados en tareas de clasificación de dígitos escritos a mano y abrió el camino para investigaciones posteriores en CNN.\n",
    "\n",
    "    - AlexNet: Lo más interesante de AlexNet es que marcó un hito importante en el campo de la visión por computadora al ganar el concurso ImageNet en 2012. Fue una de las primeras arquitecturas profundas exitosas y demostró que las CNN podían aprender características útiles de las imágenes a través del entrenamiento profundo. Su éxito revitalizó el interés en las redes neuronales profundas y condujo a avances significativos en el procesamiento de imágenes.\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LeNet-5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Imports necesarios\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Definir una transformacion para normalizar las imágenes\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Descargar el conjunto de datos y aplicar transformaciones\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Definir DataLoader para cargar los datos\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Definir la arquitectura de LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Definir una función de entrenamiento y prueba, calcular la precision como metrica\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total\n",
    "\n",
    "# Entrenar la red y evaluar la precisión\n",
    "lenet5 = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lenet5.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(lenet5, train_loader, criterion, optimizer)\n",
    "    test_acc = test(lenet5, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{10}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 24913671.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 20534954.03it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 4482203.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2704888.37it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10: Train Loss: 0.2490, Train Acc: 0.9239, Test Acc: 0.9788\n",
      "Epoch 2/10: Train Loss: 0.0653, Train Acc: 0.9797, Test Acc: 0.9812\n",
      "Epoch 3/10: Train Loss: 0.0488, Train Acc: 0.9846, Test Acc: 0.9866\n",
      "Epoch 4/10: Train Loss: 0.0382, Train Acc: 0.9885, Test Acc: 0.9877\n",
      "Epoch 5/10: Train Loss: 0.0328, Train Acc: 0.9894, Test Acc: 0.9889\n",
      "Epoch 6/10: Train Loss: 0.0270, Train Acc: 0.9915, Test Acc: 0.9883\n",
      "Epoch 7/10: Train Loss: 0.0224, Train Acc: 0.9927, Test Acc: 0.9910\n",
      "Epoch 8/10: Train Loss: 0.0199, Train Acc: 0.9937, Test Acc: 0.9903\n",
      "Epoch 9/10: Train Loss: 0.0179, Train Acc: 0.9941, Test Acc: 0.9889\n",
      "Epoch 10/10: Train Loss: 0.0153, Train Acc: 0.9952, Test Acc: 0.9891\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discusion\n",
    "\n",
    "Train Loss (Pérdida de entrenamiento): La pérdida de entrenamiento disminuye de manera constante a medida que avanzan las épocas, lo cual es un buen indicador. Esto significa que el modelo está mejorando su capacidad para ajustarse a los datos de entrenamiento.\n",
    "\n",
    "Train Accuracy (Precisión de entrenamiento): La precisión de entrenamiento aumenta a medida que avanzan las épocas, lo cual es una señal positiva. El modelo está aprendiendo y ajustándose cada vez mejor a los datos de entrenamiento.\n",
    "\n",
    "Test Accuracy (Precisión de prueba): La precisión en el conjunto de prueba también aumenta y se estabiliza en un valor alto alrededor de la época 3. Esto indica que el modelo generaliza bien a datos que no ha visto durante el entrenamiento.\n",
    "\n",
    "Resultados generales: En general, los resultados son muy buenos. El modelo LeNet-5 logra una precisión muy alta en el conjunto de prueba, superando el 98% de precisión. Esto significa que es capaz de clasificar con precisión la mayoría de los dígitos escritos a mano en el conjunto de prueba."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AlexNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Definir una transformación para normalizar las imágenes\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomCrop(32, padding=4),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Descargar el conjunto de datos CIFAR-10 y aplicar transformaciones\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Definir DataLoader para cargar los datos\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Definir la arquitectura de AlexNet\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  # Modificada para imágenes de 32x32\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "                nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Función para entrenar el modelo\n",
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return train_loss, accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Función para evaluar el modelo en el conjunto de prueba\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Entrenar la red y evaluar la precisión\n",
    "alexnet = AlexNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(alexnet.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(alexnet, train_loader, criterion, optimizer)\n",
    "    test_acc = test(alexnet, test_loader)\n",
    "    print(f'Epoch {epoch + 1}/{10}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10: Train Loss: 1454.5435, Train Acc: 28.2880, Test Acc: 37.5100\n",
      "Epoch 2/10: Train Loss: 1251.0424, Train Acc: 39.8440, Test Acc: 45.7400\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2 - Teoría\n",
    "Responda claramente y con una extensión adecuada las siguientes preguntas:\n",
    "1. Investigue e indique en qué casos son útiles las siguientes arquitecturas, agregue imagenes si esto le ayuda a una mejor comprensión\n",
    "- GoogleNet (Inception)\n",
    "\n",
    "La arquitectura GoogleNet es útil en casos donde se busca una red profunda con una computación eficiente. Su característica distintiva es el uso de módulos de \"inception\" que consisten en múltiples convoluciones y concatenaciones de características de diferentes tamaños de kernel en paralelo. Esto permite que la red capture características a diferentes escalas y resoluciones, lo que es útil en tareas de clasificación de imágenes, detección de objetos y segmentación semántica. GoogleNet es especialmente efectiva en la optimización de uso de recursos computacionales.\n",
    "\n",
    "- DenseNet (Densely Connected Convolutional Networks)\n",
    "\n",
    "DenseNet es útil cuando se busca una arquitectura que promueva conexiones densas entre capas. En lugar de tener conexiones dispersas entre capas, como en las CNN tradicionales, DenseNet conecta todas las capas entre sí. Esto fomenta el flujo de información a lo largo de la red y facilita el aprendizaje de características complejas y la mitigación del problema de desvanecimiento de gradientes. DenseNet es beneficioso para la clasificación de imágenes, detección de objetos y segmentación de imágenes.\n",
    "\n",
    "- MobileNet\n",
    "\n",
    "MobileNet es útil en casos donde se requiere una red ligera y eficiente en términos de recursos computacionales, como en aplicaciones móviles o dispositivos con recursos limitados. Esta arquitectura utiliza convoluciones separables en profundidad (depthwise separable convolutions) para reducir la cantidad de operaciones y parámetros, sin sacrificar demasiado la precisión. MobileNet es ideal para la clasificación de imágenes en dispositivos móviles y la detección en tiempo real.\n",
    "\n",
    "- EfficientNet\n",
    "\n",
    "EfficientNet es útil en situaciones donde se busca un equilibrio óptimo entre el rendimiento y la eficiencia computacional. Esta arquitectura utiliza un enfoque de búsqueda en escalas compuestas para encontrar el tamaño de modelo adecuado para una tarea dada, escalando la profundidad, el ancho y la resolución de la red de manera equilibrada. EfficientNet ha demostrado ser altamente eficiente en términos de rendimiento de precisión en una amplia gama de tareas de visión por computadora, incluida la clasificación de imágenes y la detección de objetos.\n",
    "\n",
    "2. ¿Cómo la arquitectura de transformers puede ser usada para image recognition?\n",
    "\n",
    "La arquitectura de Transformers, que se originó en el procesamiento de lenguaje natural (NLP), también se puede utilizar para el reconocimiento de imágenes. Esto se logra mediante la adaptación de la arquitectura Transformer original para el procesamiento de secuencias de texto a la tarea de procesar matrices de imágenes.\n",
    "\n",
    "El enfoque principal para usar Transformers en el reconocimiento de imágenes se llama \"Transformers para visión\" o \"Vision Transformers\". La idea central es tratar una imagen como una secuencia de parches (patches), donde cada parche es una porción de la imagen. Cada parche se representa como un vector y se pasa a través de la arquitectura Transformer.\n",
    "\n",
    "Usar Transformer con imagenes: \n",
    "\n",
    "División de la imagen en parches: La imagen se divide en una cuadrícula de parches, y cada parche se transforma en un vector de características.\n",
    "Posición de codificación: Se agrega información de posición a los vectores de características de los parches, similar a cómo se manejan las secuencias en NLP.\n",
    "Capas de atención multiatención: Se aplican capas de atención multiatención (self-attention) para permitir que los parches se relacionen entre sí.\n",
    "Redes completamente conectadas: Después de las capas de atención, se utilizan capas de redes neuronales completamente conectadas para realizar la clasificación.\n",
    "Esta arquitectura ha demostrado ser efectiva en una variedad de tareas de visión por computadora, incluido el reconocimiento de objetos, la detección de objetos y la segmentación semántica. Un ejemplo de implementación de Vision Transformer (ViT) en PyTorch se encuentra en la biblioteca \"PyTorch Vision\" de Hugging Face.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.9 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "d25cdb5aa61f08ef17d60ae5a05baad298235cb381824c57cbe25a28ddd03979"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}